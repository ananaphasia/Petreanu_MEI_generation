{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# os.chdir('Petreanu_MEI_generation')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RUN_NAME': 'test_no_grid_mean_predictor', 'ASK_FOR_CONFIRMATION': False, 'RUN_FOLDER_OVERWRITE': None, 'model': {'init_w_mean_activity': False}, 'data': {'keep_behavioral_info': False, 'area_of_interest': 'V1', 'areas_of_interest': ['V1', 'PM'], 'sessions_to_keep': 'all', 'INPUT_FOLDER': 'D:/Procdata/IM'}, 'MEIs': {'num_meis': 75, 'num_labeled_cells': 10, 'session_id': 'LPE11086', 'session_date': '2024_01_09', 'tier': 'test', 'also_output_to_local': True, 'local_output_folder': 'D:/Bonsai/lab-leopoldo-solene-vr/workflows/MEIs/', 'shape': [68, 135]}, 'dev': {'num_models': 5}, 'current_vals': {'RUN_NAME': 'V1_test_no_grid_mean_predictor', 'RUN_FOLDER': 'runs/V1_test_no_grid_mean_predictor', 'area_id': 0, 'data': {'area_of_interest': 'V1'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 16:26:32,567 - __main__ - INFO - C:\\Users\\Kerem Sarikaya\\AppData\\Local\\Temp\\ipykernel_9616\\1892001725.py - Current working directory: d:\\Python\\Anastasia\\Petreanu Lab\\Petreanu_MEI_generation\n",
      "2025-02-18 16:26:32,567 - __main__ - INFO - C:\\Users\\Kerem Sarikaya\\AppData\\Local\\Temp\\ipykernel_9616\\1892001725.py - Current working directory: d:\\Python\\Anastasia\\Petreanu Lab\\Petreanu_MEI_generation\n",
      "2025-02-18 16:26:32,567 - __main__ - INFO - C:\\Users\\Kerem Sarikaya\\AppData\\Local\\Temp\\ipykernel_9616\\1892001725.py - Saving figures to D:/OneDrive\\PostDoc\\Figures\\Images\\\n",
      "2025-02-18 16:26:32,567 - __main__ - INFO - C:\\Users\\Kerem Sarikaya\\AppData\\Local\\Temp\\ipykernel_9616\\1892001725.py - Saving figures to D:/OneDrive\\PostDoc\\Figures\\Images\\\n",
      "2025-02-18 16:26:32,599 - loaddata.session_info - INFO - d:\\Python\\Anastasia\\Petreanu Lab\\Petreanu_MEI_generation\\loaddata\\session_info.py - ['IM'] dataset: 1 mice, 1 sessions, 5600 trials\n",
      "2025-02-18 16:26:32,599 - loaddata.session_info - INFO - d:\\Python\\Anastasia\\Petreanu Lab\\Petreanu_MEI_generation\\loaddata\\session_info.py - Number of neurons in PM: 150\n",
      "2025-02-18 16:26:32,599 - loaddata.session_info - INFO - d:\\Python\\Anastasia\\Petreanu Lab\\Petreanu_MEI_generation\\loaddata\\session_info.py - Number of neurons in V1: 1592\n",
      "2025-02-18 16:26:32,599 - loaddata.session_info - INFO - d:\\Python\\Anastasia\\Petreanu Lab\\Petreanu_MEI_generation\\loaddata\\session_info.py - Total number of neurons: 1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LPE09665', '2023_03_20'], ['LPE10883', '2023_10_23'], ['LPE10883', '2023_10_31'], ['LPE10884', '2023_10_12'], ['LPE10885', '2023_10_20'], ['LPE10919', '2023_11_09'], ['LPE11086', '2023_12_16'], ['LPE11086', '2024_01_09'], ['LPE11495', '2024_02_29'], ['LPE11998', '2024_05_08'], ['LPE12223', '2024_06_11'], ['LPE13959', '2025_02_17']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecec5b0ca4714e689a7e9b519eb2f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7800b90707924b1db0c9b9ad7a1666c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for response matrix:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f371335a17ee4594b082e08b313e9dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for runspeed:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370848c2c3524b3a96a322852ab6ba76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for motion energy:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a388b5a66bde44949c45827d19008971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for pupil x position:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31556c309ea4455e9e9dbf4c4dc2b2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for pupil y position:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbe64b6190f49b781637c0646a93334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for pupil area:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e06fe03a98343d08c5d90b689205bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 16:26:45,827 - __main__ - WARNING - C:\\Users\\Kerem Sarikaya\\AppData\\Local\\Temp\\ipykernel_9616\\1892001725.py - Removing sessions idx = [] from sessions lists.\n",
      "2025-02-18 16:26:45,827 - __main__ - WARNING - C:\\Users\\Kerem Sarikaya\\AppData\\Local\\Temp\\ipykernel_9616\\1892001725.py - Removing sessions idx = [] from sessions lists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da57712095a148bebd583506bbee53d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86818ca2786415694b91152396b2ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\molanalysis\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1724: RuntimeWarning: invalid value encountered in cast\n",
      "  arr = arr.astype(dtype, copy=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b890996fad9469c85d812ebcc056dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy import ndimage\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from sensorium.utility.training import read_config\n",
    "from loaddata.session_info import load_sessions\n",
    "from utils.imagelib import load_natural_images\n",
    "from utils.tuning import mean_resp_image\n",
    "from utils.explorefigs import *\n",
    "from loaddata.get_data_folder import get_local_drive\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "\n",
    "# If you want to save a subset of the data, define these manually here. All three variables have to be defined. Else, leave this blank\n",
    "\n",
    "# session_list = np.array([['LPE10885', '2023_10_20']])\n",
    "# session_list = np.array(session_list)\n",
    "# folders = [os.path.join(INPUT_FOLDER, 'LPE10885')]\n",
    "# files = [[folder, os.path.join(folder, '2023_10_20')]\n",
    "#          for folder in folders]\n",
    "\n",
    "# Imports\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This script analyzes neural and behavioral data in a multi-area calcium imaging\n",
    "dataset with labeled projection neurons. The visual stimuli are natural images.\n",
    "Matthijs Oude Lohuis, 2023, Champalimaud Center\n",
    "Anastasia Simonoff, 2024, Bernstein Center for Computational Neuroscience Berlin\n",
    "\"\"\"\n",
    "\n",
    "# Set working directory to root of repo\n",
    "current_path = os.getcwd()\n",
    "# Identify if path has 'Petreanu_MEI_generation' as a folder in it\n",
    "if 'Petreanu_MEI_generation' in current_path:\n",
    "    # If so, set the path to the root of the repo\n",
    "    current_path = current_path.split('Petreanu_MEI_generation')[0] + 'Petreanu_MEI_generation'\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f'This needs to be run somewhere from within the Petreanu_MEI_generation folder, not {current_path}')\n",
    "os.chdir(current_path)\n",
    "sys.path.append(current_path)\n",
    "\n",
    "run_config = read_config('run_config.yaml') # Must be set\n",
    "print(run_config)\n",
    "\n",
    "# RUN_NAME = run_config['current_vals']['RUN_NAME'] # MUST be set. Creates a subfolder in the runs folder with this name, containing data, saved models, etc. IMPORTANT: all values in this folder WILL be deleted.\n",
    "RUN_NAME = 'test_new_mouse'\n",
    "# RUN_FOLDER = run_config['current_vals']['RUN_FOLDER']\n",
    "RUN_FOLDER = 'runs/test_new_mouse'\n",
    "\n",
    "keep_behavioral_info = run_config['data']['keep_behavioral_info']\n",
    "area_of_interest = run_config['current_vals']['data']['area_of_interest']\n",
    "# sessions_to_keep = run_config['data']['sessions_to_keep']\n",
    "sessions_to_keep = [['LPE13959', '2025_02_17']]\n",
    "INPUT_FOLDER = run_config['data']['INPUT_FOLDER']\n",
    "OUTPUT_FOLDER = f'{RUN_FOLDER}/data_preprocessed' # relative to molanalysis root folder\n",
    "\n",
    "# if run_config['ASK_FOR_CONFIRMATION']:\n",
    "if True:\n",
    "    input(f'RUN_NAME: {RUN_NAME}\\n\\nINPUT FOLDER: {INPUT_FOLDER}\\n\\nThis will delete all files in the {RUN_FOLDER} folder. Press Enter to continue or Ctrl+C to cancel.')\n",
    "else:\n",
    "    print(f'RUN_NAME: {RUN_NAME}\\n\\nINPUT FOLDER: {INPUT_FOLDER}\\n\\nThis will delete all files in the {RUN_FOLDER} folder. Automatically continuing...')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(pathname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# Create a StreamHandler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)  # Set the logging level for the handler\n",
    "# Create a Formatter and attach it to the handler\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(pathname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "logger.info('Current working directory: %s', os.getcwd())\n",
    "\n",
    "# TODO: Fix this so it outputs correctly during figure generation\n",
    "rmap_logger = logging.getLogger('rastermap')\n",
    "rmap_logger.setLevel(logging.WARNING)\n",
    "rmap_logger.addHandler(console_handler)\n",
    "rmap_logger.propagate = False\n",
    "\n",
    "# Updated by Anastasia Simonoff for her local computer, etc. This should be updated for your local computer, too.\n",
    "\n",
    "savedir = os.path.join(get_local_drive(\n",
    "), 'Users\\\\asimo\\\\Documents\\\\BCCN\\\\Lab Rotations\\\\Petreanu Lab\\\\Figures\\\\Images' if os.environ['USERDOMAIN'] == 'ULTINTELLIGENCE' else 'OneDrive\\\\PostDoc\\\\Figures\\\\Images\\\\')\n",
    "logger.info(f'Saving figures to {savedir}')\n",
    "\n",
    "# INPUT_FOLDER = '../sensorium/notebooks/data/IM_prezipped'\n",
    "# Add Add folders two levels deep from INPUT_FOLDER into a list\n",
    "\n",
    "# delete all files in the run folder\n",
    "if os.path.exists(RUN_FOLDER):\n",
    "    print(f'Deleting existing folder {RUN_FOLDER}')\n",
    "    shutil.rmtree(RUN_FOLDER)\n",
    "else:\n",
    "    os.makedirs(RUN_FOLDER, exist_ok=True)\n",
    "\n",
    "# Delete anything in OUTPUT_FOLDER\n",
    "try:\n",
    "    shutil.rmtree(OUTPUT_FOLDER)\n",
    "except FileNotFoundError:\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "# test if folders already defined \n",
    "try: \n",
    "    folders\n",
    "except NameError:\n",
    "    # First level\n",
    "    folders = [os.path.join(INPUT_FOLDER, name) for name in os.listdir(\n",
    "        INPUT_FOLDER) if os.path.isdir(os.path.join(INPUT_FOLDER, name)) and not \"merged_data\" in name]\n",
    "    folders = [x.replace(\"\\\\\", \"/\") for x in folders]\n",
    "    # Second level\n",
    "    files = [[folder, os.path.join(folder, name).replace('\\\\', '/')] for folder in folders for name in os.listdir(\n",
    "        folder) if os.path.isdir(os.path.join(folder, name)) and not \"merged_data\" in name]\n",
    "    # only get last value after /\n",
    "    session_list = [[folder.split(\"/\")[-1], name.split(\"/\")[-1]]\n",
    "                    for folder, name in files]\n",
    "\n",
    "    # drop ['LPE10919', '2023_11_08'] because the data is not converted yet\n",
    "    session_list = [x for x in session_list if x != ['LPE10919', '2023_11_08']]\n",
    "    print(session_list)\n",
    "\n",
    "if sessions_to_keep != 'all':\n",
    "    session_list = [x for x in session_list if x in sessions_to_keep]\n",
    "\n",
    "session_list = np.array(session_list)\n",
    "\n",
    "# Load one session including raw data: ################################################\n",
    "# example session with good responses\n",
    "\n",
    "# Load sessions lazy: (no calciumdata, behaviordata etc.,)\n",
    "sessions, nSessions = load_sessions(protocol='IM', session_list=session_list, data_folder=INPUT_FOLDER)\n",
    "\n",
    "# Load proper data and compute average trial responses:\n",
    "for ises in tqdm(range(nSessions)):    # iterate over sessions\n",
    "\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, session_list[ises][0], session_list[ises][1], 'data'), exist_ok=True)\n",
    "\n",
    "    sessions[ises].load_respmat(calciumversion='deconv', keepraw=True)\n",
    "\n",
    "    # Save respmat\n",
    "    # np.save(os.path.join(files[ises][1], 'respmat.npy'), sessions[ises].respmat)\n",
    "    np.save(os.path.join(OUTPUT_FOLDER, session_list[ises][0], session_list[ises][1], 'data', 'respmat.npy'), sessions[ises].respmat)\n",
    "\n",
    "# Load all IM sessions including raw data: ################################################\n",
    "# sessions,nSessions   = filter_sessions(protocols = ['IM'])\n",
    "# for ises in range(nSessions):    # iterate over sessions\n",
    "#     sessions[ises].load_respmat(calciumversion='deconv',keepraw=False)\n",
    "\n",
    "def replace_nan_with_avg(arr):\n",
    "    arr = arr.copy()  # Copy the array to avoid modifying the original\n",
    "    nan_indices = np.where(np.isnan(arr))[0]  # Get indices of NaN values\n",
    "\n",
    "    for i in nan_indices:\n",
    "        # Handle cases where NaN is at the start or end of the array\n",
    "        if i == 0:\n",
    "            arr[i] = arr[i + 1]\n",
    "        elif i == len(arr) - 1:\n",
    "            arr[i] = arr[i - 1]\n",
    "        else:\n",
    "            # Replace NaN with the average of adjacent values\n",
    "            arr[i] = np.nanmean([arr[i - 1], arr[i + 1]])\n",
    "\n",
    "    return arr\n",
    "\n",
    "# Save behavior data in sensorium format\n",
    "\n",
    "idx_to_delete = []\n",
    "\n",
    "for i, (sess, sess_obj) in enumerate(zip(session_list, sessions)):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "\n",
    "    pupil_size = sess_obj.respmat_pupilarea.reshape(-1, 1)\n",
    "    change_of_pupil_size = sess_obj.respmat_pupilareaderiv.reshape(-1, 1)\n",
    "    locotomion_speed = sess_obj.respmat_runspeed.reshape(-1, 1)\n",
    "\n",
    "    # Data\n",
    "    folder = f'{folder_base}/data/behavior'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    if np.isnan(pupil_size).all() or np.isnan(change_of_pupil_size).all() or np.isnan(locotomion_speed).all():\n",
    "        logger.warning(\n",
    "            f'All values in behavior data for session {sess[0]}/{sess[1]} are NaN. Session will be removed.')\n",
    "        # Drop session from list\n",
    "        # session_list = np.delete(session_list, i, axis=0)\n",
    "        # sessions = np.delete(sessions, i, axis=0)\n",
    "        idx_to_delete.append(i)\n",
    "        # Remove folder\n",
    "        shutil.rmtree(folder_base)\n",
    "        try:\n",
    "            os.rmdir(folder_base)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(f'{INPUT_FOLDER}/{sess[0]}/{sess[1]}/')\n",
    "            if len(os.listdir(f'{INPUT_FOLDER}/{sess[0]}')) == 0:\n",
    "                os.rmdir(f'{INPUT_FOLDER}/{sess[0]}/')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        continue\n",
    "\n",
    "    behavior = np.hstack((pupil_size, change_of_pupil_size, locotomion_speed))\n",
    "    if keep_behavioral_info:\n",
    "        behavior = replace_nan_with_avg(behavior)\n",
    "        assert not np.isnan(behavior).any(), 'There are still NaN values in the behavior data'\n",
    "    else:\n",
    "        behavior = np.random.default_rng().normal(size=behavior.shape)\n",
    "\n",
    "    for i in tqdm(range(behavior.shape[0])):\n",
    "        np.save(f'{folder}/{i}.npy', behavior[i, :])\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/behavior/all'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(behavior, axis=0)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(behavior, axis=0)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(behavior, axis=0)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(behavior, axis=0)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(behavior, axis=0)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/behavior/stimulus_Frame'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(behavior, axis=0)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(behavior, axis=0)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(behavior, axis=0)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(behavior, axis=0)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(behavior, axis=0)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "logger.warning(f'Removing sessions idx = {idx_to_delete} from sessions lists.')\n",
    "session_list = np.delete(session_list, idx_to_delete, axis=0)\n",
    "sessions = np.delete(sessions, idx_to_delete, axis=0)\n",
    "\n",
    "### Load the natural images:\n",
    "# natimgdata = load_natural_images(onlyright=True)\n",
    "natimgdata = load_natural_images()\n",
    "natimgdata = natimgdata[:, natimgdata.shape[1]//2:, :]  # Only take the right half\n",
    "\n",
    "# Save natimgdata in sensorium format\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "\n",
    "    folder = f'{folder_base}/data/images'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    image_idxs = sess_obj.trialdata['ImageNumber'].values\n",
    "\n",
    "    for i, imgidx in tqdm(enumerate(image_idxs), total=len(image_idxs)):\n",
    "        file_name = f'{folder}/{i}.npy'\n",
    "        img = natimgdata[:, :, imgidx]\n",
    "        img = np.reshape(img, (-1, img.shape[0], img.shape[1]))\n",
    "        np.save(file_name, img)  # hacky but works\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/images/all'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(natimgdata)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(natimgdata)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(natimgdata)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(natimgdata)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(natimgdata)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/images/stimulus_Frame'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(natimgdata)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(natimgdata)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(natimgdata)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(natimgdata)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(natimgdata)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "# Save pupil center data in sensorium format\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/data/pupil_center'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    pupil_x = sess_obj.respmat_pupilx.reshape(-1, 1)\n",
    "    pupil_y = sess_obj.respmat_pupily.reshape(-1, 1)\n",
    "\n",
    "    pupil_center = np.hstack((pupil_x, pupil_y))\n",
    "\n",
    "    if keep_behavioral_info:\n",
    "        pupil_center = replace_nan_with_avg(pupil_center)\n",
    "\n",
    "        while np.isnan(pupil_center).any():\n",
    "            pupil_center = replace_nan_with_avg(pupil_center)\n",
    "    else:\n",
    "        pupil_center = np.random.default_rng().normal(size=pupil_center.shape)\n",
    "\n",
    "    for i in tqdm(range(pupil_center.shape[0])):\n",
    "        np.save(f'{folder}/{i}.npy', pupil_center[i, :])\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/pupil_center/all'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/pupil_center/stimulus_Frame'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(pupil_center, axis=0)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "# Add neuron data\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/meta/neurons'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    celldata = sess_obj.celldata.copy()\n",
    "\n",
    "    # layer\n",
    "    # V1\n",
    "    celldata.loc[(celldata['roi_name'] == 'V1') & (\n",
    "        celldata['depth'] < 250), 'layer'] = 'L2/3'\n",
    "    celldata.loc[(celldata['roi_name'] == 'V1') & (\n",
    "        celldata['depth'] >= 250) & (celldata['depth'] < 350), 'layer'] = 'L4'\n",
    "    celldata.loc[(celldata['roi_name'] == 'V1') & (\n",
    "        celldata['depth'] >= 350), 'layer'] = 'L5/6'\n",
    "\n",
    "    # PM\n",
    "    celldata.loc[(celldata['roi_name'] == 'PM') & (\n",
    "        celldata['depth'] < 250), 'layer'] = 'L2/3'\n",
    "    celldata.loc[(celldata['roi_name'] == 'PM') & (\n",
    "        celldata['depth'] >= 250) & (celldata['depth'] < 325), 'layer'] = 'L4'\n",
    "    celldata.loc[(celldata['roi_name'] == 'PM') & (\n",
    "        celldata['depth'] >= 325), 'layer'] = 'L5'\n",
    "    \n",
    "    celldata = celldata.loc[celldata['roi_name'] == area_of_interest] if area_of_interest is not None else celldata\n",
    "    \n",
    "    # Save celldata to obj\n",
    "    sess_obj.celldata = celldata.copy()\n",
    "\n",
    "    num_neurons = len(celldata)\n",
    "    \n",
    "    # layer\n",
    "    np.save(f'{folder}/layer.npy',\n",
    "            celldata['layer'].to_numpy(dtype='<U32'))\n",
    "    \n",
    "    # animal ids\n",
    "    np.save(f'{folder}/animal_ids.npy',\n",
    "            np.full((num_neurons, ), sess_obj.animal_id, dtype='<U32'))\n",
    "\n",
    "    # area\n",
    "    np.save(f'{folder}/area.npy',\n",
    "            celldata['roi_name'].to_numpy(dtype='<U32'))\n",
    "\n",
    "    # cell motor coordinates\n",
    "    np.save(f'{folder}/cell_motor_coordinates.npy',\n",
    "            celldata[['xloc', 'yloc', 'depth']].to_numpy(dtype=int))\n",
    "\n",
    "    # scan idx\n",
    "    np.save(f'{folder}/scan_idx.npy',\n",
    "            np.full((num_neurons, ), 0))\n",
    "\n",
    "    # sessions\n",
    "    np.save(f'{folder}/sessions.npy',\n",
    "            celldata['session_id'].to_numpy(dtype='<U32'))\n",
    "\n",
    "    # unit ids\n",
    "    np.save(f'{folder}/unit_ids.npy',\n",
    "            celldata['cell_id'].to_numpy(dtype='<U32'))\n",
    "\n",
    "# Save responses in sensorium format\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/data/responses'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    responses = sess_obj.respmat\n",
    "    responses = replace_nan_with_avg(responses)\n",
    "\n",
    "    celldata = sess_obj.celldata.copy()\n",
    "\n",
    "    responses = responses[celldata.index.values]\n",
    "\n",
    "    sess_obj.respmat = responses\n",
    "\n",
    "    for i in tqdm(range(responses.shape[1])):\n",
    "        np.save(f'{folder}/{i}.npy', responses[:, i])\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/responses/all'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(responses, axis=1)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(responses, axis=1)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(responses, axis=1)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(responses, axis=1)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(responses, axis=1)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/responses/stimulus_Frame'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(responses, axis=1)\n",
    "    np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(responses, axis=1)\n",
    "    np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(responses, axis=1)\n",
    "    np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(responses, axis=1)\n",
    "    np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(responses, axis=1)\n",
    "    np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "def calculate_tiers(num_images):\n",
    "    # Split into train/test/validate\n",
    "    idxs = np.arange(num_images)\n",
    "    np.random.shuffle(idxs)\n",
    "    train_idxs = idxs[:int(num_images * 0.75)]\n",
    "    test_idxs = idxs[int(num_images * 0.75):int(num_images * 0.916)]\n",
    "    validate_idxs = idxs[int(num_images * 0.916):]\n",
    "    return train_idxs, test_idxs, validate_idxs\n",
    "\n",
    "# Add trial data\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/meta/trials'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    trial_data = sess_obj.trialdata.copy()\n",
    "    num_trials = trial_data.shape[0]\n",
    "\n",
    "    # album\n",
    "    # ???\n",
    "    np.save(f'{folder}/album.npy',\n",
    "            np.full((num_trials,), 'UNK', dtype='<U32'))\n",
    "\n",
    "    # animal id\n",
    "    np.save(f'{folder}/animal_id.npy',\n",
    "            np.full((num_trials,), sess_obj.animal_id, dtype='<U32'))\n",
    "\n",
    "    # condition hash\n",
    "    # ???\n",
    "    np.save(f'{folder}/condition_hash.npy',\n",
    "            np.full((num_trials,), 'UNK', dtype='<U32'))\n",
    "\n",
    "    # frame image class\n",
    "    # ???\n",
    "    np.save(f'{folder}/frame_image_class.npy',\n",
    "            np.full((num_trials,), 'UNK', dtype='<U32'))\n",
    "\n",
    "    # frame image id\n",
    "    np.save(f'{folder}/frame_image_id.npy', trial_data['ImageNumber'].values)\n",
    "\n",
    "    # frame last flip\n",
    "    # ???\n",
    "    np.save(f'{folder}/frame_last_flip.npy',\n",
    "            np.full((num_trials,), 0))\n",
    "\n",
    "    # frame pre blank period\n",
    "    trial_data['tOnset'] = pd.to_datetime(trial_data['tOnset'], unit='s')\n",
    "    trial_data['tOffset'] = pd.to_datetime(trial_data['tOffset'], unit='s')\n",
    "    trial_data['presentationTime'] = trial_data['tOffset'] - \\\n",
    "        trial_data['tOnset']\n",
    "\n",
    "    # calculate inter image interval\n",
    "    trial_data['tOffset_prev'] = trial_data['tOffset'].shift(1)\n",
    "    trial_data['tIntertrial'] = trial_data['tOnset'] - \\\n",
    "        trial_data['tOffset_prev']\n",
    "    trial_data['tIntertrial'].fillna(pd.Timedelta(seconds=0.5), inplace=True)\n",
    "    trial_data['tIntertrial'] = trial_data['tIntertrial'].dt.total_seconds()\n",
    "    np.save(f'{folder}/frame_pre_blank_period.npy',\n",
    "            trial_data['tIntertrial'].values)\n",
    "\n",
    "    # frame presentation time\n",
    "    np.save(f'{folder}/frame_presentation_time.npy',\n",
    "            trial_data['presentationTime'].dt.total_seconds())\n",
    "\n",
    "    # frame_trial_ts\n",
    "    np.save(f'{folder}/frame_trial_ts.npy', trial_data['tOnset'].apply(\n",
    "        lambda x: f\"Timestamp('{x}')\").to_numpy(dtype='<U32'))\n",
    "\n",
    "    # scan_idx\n",
    "    # ???\n",
    "    np.save(f'{folder}/scan_idx.npy',\n",
    "            np.full((num_trials,), 0))\n",
    "\n",
    "    # session\n",
    "    np.save(f'{folder}/session.npy',\n",
    "            np.full((num_trials,), sess_obj.session_id))\n",
    "\n",
    "    # tiers\n",
    "    trial_data['ImageCount'] = trial_data['ImageNumber'].map(\n",
    "        trial_data['ImageNumber'].value_counts())\n",
    "    trial_data['ImagePresentation'] = trial_data.groupby(\n",
    "        'ImageNumber').cumcount() + 1\n",
    "\n",
    "    # Assign tiers to images\n",
    "    for i, group in trial_data.groupby('ImageCount'):\n",
    "        for j, group2 in group.groupby('ImagePresentation'):\n",
    "            train_idxs, test_idxs, validate_idxs = calculate_tiers(\n",
    "                group2.shape[0])\n",
    "\n",
    "            # Update indices\n",
    "            train_idxs = group2.index[train_idxs]\n",
    "            test_idxs = group2.index[test_idxs]\n",
    "            validate_idxs = group2.index[validate_idxs]\n",
    "\n",
    "            # assign to tiers\n",
    "            trial_data.loc[train_idxs, 'tiers'] = 'train'\n",
    "            trial_data.loc[test_idxs, 'tiers'] = 'test'\n",
    "            trial_data.loc[validate_idxs, 'tiers'] = 'validation'\n",
    "\n",
    "    np.save(f'{folder}/tiers.npy',\n",
    "            trial_data['tiers'].to_numpy(dtype='<U32'))\n",
    "\n",
    "    # trial_idx\n",
    "    np.save(f'{folder}/trial_idx.npy', trial_data['TrialNumber'].values)\n",
    "\n",
    "# Calculate mean activity\n",
    "\n",
    "def get_response_triggered_image(ses, natimgdata):\n",
    "    \n",
    "    respmean,imageids   = mean_resp_image(ses)\n",
    "\n",
    "    N                   = np.shape(ses.respmat)[0]\n",
    "\n",
    "    # Compute response triggered average image:\n",
    "    ses.RTA             = np.empty((*np.shape(natimgdata)[:2], N))\n",
    "    weight_sums = np.sum(respmean, axis = 1)\n",
    "    ses.RTA = np.tensordot(natimgdata[:,:,imageids], respmean, axes=([2], [1])) / weight_sums\n",
    "        \n",
    "    return ses\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "\n",
    "    sess_obj.celldata['rf_az_F'] = sess_obj.celldata['rf_el_F'] = sess_obj.celldata['rf_r2_F'] = np.nan\n",
    "\n",
    "    az_lims = [-1, 1]\n",
    "    el_lims = [-1, 1] # for converting to mean neuronal activity for gaussian.py\n",
    "\n",
    "    if not hasattr(sess_obj,'RTA'):\n",
    "        sess_obj         = get_response_triggered_image(sess_obj, natimgdata)\n",
    "\n",
    "    ypix,xpix,N = np.shape(sess_obj.RTA)\n",
    "    xmap        = np.linspace(*az_lims,xpix)\n",
    "    ymap        = np.linspace(*el_lims,ypix)\n",
    "    # N = 100\n",
    "    zthr        = 3\n",
    "    rf_data     = pd.DataFrame(data=np.full((N,2),np.nan),columns=['rf_az_F','rf_el_F'])\n",
    "\n",
    "    for iN in range(N):\n",
    "        dev = zscore(sess_obj.RTA[:, :, iN].copy()-128,axis=None)\n",
    "        dev[np.abs(dev)<zthr]=0\n",
    "        if np.any(dev):\n",
    "            (y, x) = np.round(ndimage.center_of_mass(np.abs(dev))).astype(int) # have to flip x and y because this gives row and column instead of x and y in image space\n",
    "            rf_data.loc[iN,'rf_az_F'] = xmap[x]\n",
    "            rf_data.loc[iN,'rf_el_F'] = ymap[y]\n",
    "\n",
    "    # Save rf_data\n",
    "    out_mat = rf_data.to_numpy()\n",
    "    out_mat = replace_nan_with_avg(out_mat)\n",
    "\n",
    "    # assert there are no nan values\n",
    "    # assert not np.isnan(out_mat).any(), f'There are still NaN values in the rf_data for session {sess[0]}/{sess[1]}'\n",
    "    if np.isnan(out_mat).any():\n",
    "        print(f'There are still {np.sum(np.isnan(out_mat))} NaN values in the rf_data for session {sess[0]}/{sess[1]}')\n",
    "        print(f'NaN indices, {np.argwhere(np.isnan(out_mat))}')\n",
    "\n",
    "    # Reshape to (1, N, 1, 2)\n",
    "    # out_mat = np.expand_dims(out_mat, axis=0)\n",
    "    # out_mat = np.expand_dims(out_mat, axis=2)\n",
    "    \n",
    "    # to torch tensor\n",
    "    out_mat = torch.tensor(out_mat, dtype=torch.float32)\n",
    "    # save\n",
    "    folder = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}/meta/neurons'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    torch.save(out_mat, f'{folder}/rf_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4030,  0.4627],\n",
       "        [ 0.0448,  0.1642],\n",
       "        [ 0.1791,  0.3134],\n",
       "        ...,\n",
       "        [-0.1343,  0.1045],\n",
       "        [ 0.1045,  0.1045],\n",
       "        [ 0.2985,  0.5522]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
